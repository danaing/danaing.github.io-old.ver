---
layout: post
title:  "[TensorFlow] Introduction to TensorFlow (DeepLearning.AI)"
date:   2021-05-17
author: danahkim
tags: TensorFlow
categories: DeepLearning
---

## 0. ë“¤ì–´ê°€ë©°

TensorFlow Developer Certificateë¥¼ ì·¨ë“í•˜ê¸° ìœ„í•´ ìˆ˜ê°•í•œ Courseraì˜ [DeepLearning.AI TensorFlow ê°œë°œì ì „ë¬¸ ìê²©ì¦ ê°•ì˜](https://www.coursera.org/professional-certificates/tensorflow-in-practice)ì˜ [**Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning**](https://www.coursera.org/learn/introduction-tensorflow/) ê°•ì¢Œë¥¼ ìˆ˜ê°•í•˜ì˜€ìŠµë‹ˆë‹¤.

![](/assets/images/2021-05-17-coursera--67ad01c3.png)

ë³¸ ê°•ì¢ŒëŠ” 2ëª…ì˜ ê°•ì‚¬ê°€ ë‚˜ì˜µë‹ˆë‹¤. Googleì—ì„œ AI Advocacyë¥¼ ì´ëŒê³  ìˆëŠ” **Laurence Moroney** ê°€ ì§ì ‘ DeepLearningê³¼ TensorFlowì— ëŒ€í•´ ê°•ì˜í•˜ì‹œê³ , Stanford ëŒ€í•™ì˜ ìœ ëª… êµìˆ˜ì¸ **Andrew Ng** êµìˆ˜ë‹˜ì´ ë‹´í™”ì— ë‚˜ì˜¤ì‹­ë‹ˆë‹¤.

TensorFlowì— ëŒ€í•œ ë§ì€ ì±…ê³¼ ê°•ì˜ê°€ ìˆì§€ë§Œ, ì´ ê°•ì¢Œë¥¼ ìˆ˜ê°•í•œ ì´ìœ ëŠ” êµ¬ê¸€ì˜ ì €ëª…í•œ ê³¼í•™ìê°€ 'ì§ì ‘' ì„¤ëª…í•˜ëŠ” Deeplearningê³¼ TensorFlowëŠ” ì–´ë–¤ê±¸ì§€ ê¶ê¸ˆí–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì§‘ì—ì„œ í¸íˆ ì•‰ì•„ì„œ êµ¬ê¸€ ê³¼í•™ìì˜ ê°•ì˜ë¥¼ ë“¤ì„ ìˆ˜ ìˆë‹¤ë‹ˆ ì–¼ë§ˆë‚˜ í° í˜ëª…ì¸ê°€ìš”?

Class materialê³¼ ì œê°€ í‘¼ exerciseëŠ” ì œ [Github ë§í¬](https://github.com/danaing/Coursera-TensorFlow/)ì— ì •ë¦¬í•´ë‘ì—ˆìŠµë‹ˆë‹¤.

-----------
## 1. A New Programming Paradigm

![](/assets/images/2021-05-17-coursera--10e0800b.png)

> "We built a super simple neural network that fit data like an x and y data onto a line but that was just **"Hello, World"**. Right, Andrew? So fitting straight lines seems like the "Hello, world" most basic implementation learning algorithm."

ë¨¼ì € ë¨¸ì‹ ëŸ¬ë‹ì™€ ë”¥ëŸ¬ë‹ì— ëŒ€í•œ ê°œìš”ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì»´í“¨í„° ì–¸ì–´ë¥¼ ë°°ìš°ê¸° ì‹œì‘í•  ë•Œ ìœ¼ë ˆ ê·¸ **ì„¸ê³„ ì…ë¬¸ ì˜ì‹**ìœ¼ë¡œ `Hello, World!`ë¥¼ ë¨¼ì € í”„ë¦°íŠ¸í•˜ê³¤ í•©ë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì„¸ê³„ì— ì…ë¬¸í•  ë•ŒëŠ” xì™€ yì˜ simple linear regressionì„ ë¨¼ì € fittingí•˜ëŠ” ê²ƒì´ 'Hello, World!'ì™€ ê°™ë‹¤ëŠ” ë‹´í™”ê°€ ì¸ìƒê¹Šì—ˆìŠµë‹ˆë‹¤.

ì•„ë˜ì™€ ê°™ì€ $x$ì™€ $y$ì˜ 1ì°¨ ì„ í˜• ê´€ê³„ê°€ ìˆì„ ë•Œ, Neural Net 1ê°œì— fittingí•˜ì—¬ Simple Linear Regressionë¬¸ì œë¥¼ í•´ê²°í•´ë³´ê² ìŠµë‹ˆë‹¤.

$$
y = 0.5x + 0.5
$$

TensorFlowëŠ” Kerasì˜ Sequentialì„ ì‚¬ìš©í•˜ì—¬ Neural Networks Modelì„ í•œì¤„ë¡œ ê°„ë‹¨íˆ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. *(ì €ëŠ” ì´ê²Œ ì´ ì£¼ì°¨ì˜ ì´ë¦„ì¸ 'ìƒˆë¡œìš´ í”„ë¡œê·¸ë˜ë° íŒ¨ëŸ¬ë‹¤ì„'ì„ ëœ»í•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.)* Optimizerì™€ loss, epochì„ ì§€ì •í•˜ê³  ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì— fittingí•©ë‹ˆë‹¤.

```python
import tensorflow as tf
import numpy as np
from tensorflow import keras

model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
model.compile(optimizer='sgd', loss='mean_squared_error')
xs = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], dtype=float)
ys = np.array([1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)
model.fit(xs, ys, epochs=1000)
print(model.predict([7.0]))
```

![](/assets/images/2021-05-17-coursera--05d65183.png)

epoch 1000ìœ¼ë¡œ ëª¨í˜• í•™ìŠµì´ ëë‚¬ìŠµë‹ˆë‹¤. $ x=7 $ ì„ predictí•œ ê²°ê³¼ $ y=4 $ê°€ ì•„ë‹ˆë¼ $ 4.0027223 $ìœ¼ë¡œ $ 4 $ì— ë§¤ìš° ê·¼ì ‘í•œ ìˆ«ìê°€ ë‚˜ì˜µë‹ˆë‹¤. ì´ëŠ” ëª¨í˜•ì´ í™•ë¥ ì ìœ¼ë¡œ ì ‘ê·¼í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ìì—°ìŠ¤ëŸ¬ìš´ í˜„ìƒì…ë‹ˆë‹¤.

-----------
## 2. Introduction to Computer Vision

Neuralì„ ê¹Šê²Œ ìŒ“ëŠ” Deap Neural Networkë¥¼ ì‚¬ìš©í•œ image classificationì€ Computer Visionì˜ ì…ë¬¸ì…ë‹ˆë‹¤.

í‘ë°± ì´ë¯¸ì§€ì˜ **fashion mnist** ë°ì´í„°ì…‹ìœ¼ë¡œ ì˜ˆë¥¼ ë“¤ê² ìŠµë‹ˆë‹¤. í‘ë°± ìƒ‰ìƒì€ 0ê³¼ 255 ì‚¬ì´ì˜ pixel ê°’ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¤ì–‘í•œ ì´ìœ ë¡œ ëª¨ë“  ê°’ì´ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§ˆ ë•Œ ë‹¤ë£¨ê¸° ì‰¬ìš°ë¯€ë¡œ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë„ë¡ Normalizeí•©ë‹ˆë‹¤.

* **Sequential**: neural networkì—ì„œ layerì˜ ìˆœì„œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
* **Flatten**: ì´ë¯¸ì§€ëŠ” ì‚¬ê°í˜•ì´ê¸° ë•Œë¬¸ì— Flattenì„ ì‚¬ìš©í•˜ì—¬ 1-dimensional-setìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤ë‹ˆë‹¤. inpute_shapeì„ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì˜ ì§€ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 28*28 í–‰ë ¬ ì´ë¯¸ì§€ëŠ” 784 ë²¡í„°ê°€ ë©ë‹ˆë‹¤.
* **Dense**: ë‰´ëŸ°ì¸µì„ ì¶”ê°€í•©ë‹ˆë‹¤.

ê°ê°ì˜ layerëŠ” activation fuctionì´ í•„ìš”í•œë° 'Relu'ì™€ 'Softmax' í•¨ìˆ˜ë¥¼ optionìœ¼ë¡œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

íŠ¹íˆ **Callback**ì„ ì¶”ê°€í•˜ì—¬ ìì‹ ì´ ì›í•˜ëŠ” ì„±ëŠ¥ì— ë„ë‹¬í•˜ë©´ í•™ìŠµì„ ë©ˆì¶”ê²Œ í•˜ëŠ” ë°©ë²•ì´ ìœ ìš©í•©ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œì— myCallbackì´ë¼ëŠ” classë¥¼ ë³´ë©´ 99%ì˜ Accuracyë¥¼ ë‹¬ì„±í•˜ë©´ í•™ìŠµì´ ë©ˆì¶”ê²Œ ë©ë‹ˆë‹¤.

```Python
import tensorflow as tf

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('acc')>=0.99):
      print("\nReached 99% accuracy so cancelling training!")
      self.model.stop_training = True

callbacks = myCallback()
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()

# Normalize the images
training_images=training_images/255.0
test_images=test_images/255.0

model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])
```

![](/assets/images/2021-05-17-coursera--4e5c667d.png)

Accuracyê°€ 99%ì— ë„ë‹¬í•˜ì—¬ í•™ìŠµì´ ì¤‘ë‹¨ëœ ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

-----------
## 3. Enhancing Vision with Convolutional Neural Networks

( â†’ Course MaterialsëŠ” [ì—¬ê¸°](https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%206%20-%20Lesson%202%20-%20Notebook.ipynb)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. )

ìœ„ DNNì—ì„œ ë ˆì´ì–´ ì¸µì˜ í¬ê¸°, í•™ìŠµ epochì˜ ìˆ˜ê°€ Accurayì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ëª¨ë¸ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```Python
import tensorflow as tf
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images / 255.0
test_images=test_images / 255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=5)

test_loss = model.evaluate(test_images, test_labels)
```

![](/assets/images/2021-05-17-coursera--436b07cf.png)

ìœ„ DNN ëª¨ë¸ì˜ Test AccuracyëŠ” ì•½ 87% ì…ë‹ˆë‹¤.

ì„±ëŠ¥ì„ ì–´ë–»ê²Œ ë” í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì„ê¹Œìš”? í•œ ê°€ì§€ ë°©ë²•ì€ **Convolutions**ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
[ìœ„í‚¤í”¼ë””ì•„](https://en.wikipedia.org/wiki/Kernel_(image_processing))ì— ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” Convolution matrix(also called as kernel or mask) ì— ëŒ€í•œ ì •ë¦¬ê°€ ì˜ ë˜ì–´ìˆìœ¼ë‹ˆ ì°¸ê³ í•´ì£¼ì„¸ìš”!

Convolutionsë¥¼ ì¶”ê°€í•œ Neural Networkì˜ ê¶ê·¹ì ì¸ ì»¨ì…‰ì€ **êµ¬ì²´ì ì´ê³  ëšœë ·í•œ ë””í…Œì¼ì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ì¤„ì´ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.

ë˜í•œ kernel ì•ˆì—ì„œ ê°€ì¥ í° ê°’ë§Œ ê°€ì ¸ì˜¤ëŠ” **MaxPooling**ì„ ì‚¬ìš©í•˜ì—¬ ê°•ì¡° íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
![](/assets/images/2021-05-17-coursera--057e5d56.png)
<center> <small> ì¶œì²˜: https://youtu.be/8oOgPUO-TBY </small> </center> <br/>

```Python
import tensorflow as tf
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images.reshape(60000, 28, 28, 1)
training_images=training_images / 255.0
test_images = test_images.reshape(10000, 28, 28, 1)
test_images=test_images/255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()
model.fit(training_images, training_labels, epochs=5)
test_loss = model.evaluate(test_images, test_labels)
```

![](/assets/images/2021-05-17-coursera--e4add9d1.png)

ë˜‘ê°™ì´ 5ê°œì˜ epochì—ì„œ CNNì˜ ì„±ëŠ¥ì€ Test Accuracyê°€ ì•½ 90%ë¡œ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!

ê·¸ë ‡ë‹¤ë©´ DNNê³¼ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¼ê¹Œìš”?
ë¨¼ì € CNNì€ trainì´ ë” ëŠë¦¬ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì»¨í´ë£¨ì…˜ê³¼ í’€ë§ì´ íš¨ìœ¨ì„±ê³¼ í•™ìŠµì— ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ë•Œë¬¸ì— lossë„ ë” ë‚®ê³ , Accuracyë„ ë” ë†’ìŠµë‹ˆë‹¤. í•œë§ˆë””ë¡œ ì´ë¯¸ì§€ ë°ì´í„°ì— CNNì˜ ì„±ëŠ¥ì´ í›¨ì”¬ ì¢‹ìŠµë‹ˆë‹¤.


#### (ì°¸ê³ ) Convolutional Neural Networks by Andrew Ng
Covolutional Neural Networks ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´, ì•„ë˜ ë§í¬ì˜ Andrew Ng êµìˆ˜ë‹˜ì˜ ê°•ì˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
Courseraì—  Convolutional Neural Networks (Course 4 of the Deep Learning Specialization) ì½”ìŠ¤ë¡œë„ ìˆìŠµë‹ˆë‹¤.
* Youtube ë§í¬: <https://bit.ly/2UGa7uH>

-----------
## 4. Using Real-world Images

ê°„ë‹¨í•˜ê²Œ Convolutionë§Œ ì¶”ê°€í•´ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒí•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ë³´ë‹¤ì‹œí”¼ ìœ„ì˜ fashion mnistë¥¼ ë¶„ë¥˜í•œ ëª¨ë¸ì€ ë‚˜ì˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë°©ë²•ì€ ë³µì¡í•œ í˜„ì‹¤ ì´ë¯¸ì§€ì—ë„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê·¸ëŸ¬ë‚˜ CNN ë°©ë²•ì˜ ë‹¨ì ì€ ì´ë¯¸ì§€ê°€ ì•„ì£¼ uniformí•´ì•¼í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. fashion mnistëŠ” ëª¨ë‘ fashionì´ë¼ëŠ” í•˜ë‚˜ì˜ ì£¼ì œì— ê´€í•œ ì´ë¯¸ì§€ì´ê³ , ëª¨ë‘ ê°€ìš´ë°ì— ìœ„ì¹˜í•˜ë©° í™•ëŒ€ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ë¯¸ì§€ í¬ê¸°ê°€ ëª¨ë‘ 28*28ë¡œ ë™ì¼í•©ë‹ˆë‹¤.

*í•˜ì§€ë§Œ ë§ì€ í˜„ì‹¤ ë°ì´í„°ëŠ” ê·¸ë ‡ê²Œ uniformí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.* GoogleAPIì—ì„œ ì œê³µí•˜ëŠ” ë§ê³¼ ì‚¬ëŒì„ ë¶„ë¥˜í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì˜ˆì‹œë¡œ ë³´ê² ìŠµë‹ˆë‹¤.

![](/assets/images/2021-05-17-coursera--56e1f522.png)
<center> <small> horse-or-human dataset </small> </center> <br/>

ìœ„ ì´ë¯¸ì§€ë¥¼ ë³´ë©´ ë‹¤ë¥¸ ìƒ‰ê¹”, ë‹¤ë¥¸ ìƒê¹€ìƒˆì˜ ë§ê³¼ ë‹¤ë¥¸ ì„±ë³„ê³¼ ì™¸ëª¨, ë‹¤ì–‘í•œ ìì„¸ë¥¼ ì·¨í•œ ì—¬ëŸ¬ ì¸ë¬¼ ì‚¬ì§„ì´ ìˆìŠµë‹ˆë‹¤. ì‹¬ì§€ì–´ ë§ì˜ ë‹¤ë¦¬ê°€ 3ê°œë§Œ ë‚˜ì˜¨ ê²ƒë„ ìˆê³ , ì‚¬ëŒ ë‹¤ë¦¬ê°€ ì¤‘ê°„ê¹Œì§€ë§Œ ë‚˜ì˜¨ ê²ƒë„ ìˆìŠµë‹ˆë‹¤. ì´ ì´ë¯¸ì§€ë¥¼ ê°€ì§€ê³  binary-classificationì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.

ì²«ë²ˆì§¸ í• ì¼ì€ ë°”ë¡œ 'ì‰½ê²Œ' ì–´ë–¤ ì´ë¯¸ì§€ê°€ ì‚¬ëŒì´ê³  ë§ì¸ì§€ labelingí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. TensorFlowì— **ImageDataGenerator**ë¼ëŠ” ìœ ìš©í•œ í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ë¶„ë¥˜ ëª¨í˜•ì„ ë§Œë“¤ ë•Œ classì— ëŒ€í•œ labelingì´ í•„ìš”í•œë°, ì´ë¯¸ì§€ì— ëŒ€í•œ labelingì„ subdirectoryë¥¼ ì‚¬ìš©í•˜ì—¬ ì‰½ê²Œ ë„ì™€ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.

![](/assets/images/2021-05-17-coursera--a6d86419.png)
<center> <small> ì¶œì²˜: https://youtu.be/0kYIZE8Gl90 </small> </center> <br/>

ìœ„ì˜ directory êµ¬ì¡°ë¥¼ ë³´ë©´, Training ì•ˆì— Horsesì™€ Humansë¼ëŠ” directoryê°€ ìˆê³  ê·¸ ì•ˆì— ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ImageDataGeneratorëŠ” directory ì´ë¦„ì— ë”°ë¼ ìë™ìœ¼ë¡œ labelingì„ í•´ì¤ë‹ˆë‹¤. ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```Python
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_dir = '/tmp/horse-or-human/'
# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1/255)

# Flow training images in batches of 128 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        train_dir,  # This is the source directory for training images
        target_size=(300, 300),  # All images will be resized to 150x150
        batch_size=128,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='binary')

validation_dir = '/tmp/validation-horse-or-human/'
# All images will be rescaled by 1./255
validation_datagen = ImageDataGenerator(rescale=1/255)

# Flow validation images in batches of 32 using validation_datagen generator
validation_generator = validation_datagen.flow_from_directory(
        validation_dir,  # This is the source directory for training images
        target_size=(300, 300),  # All images will be resized to 150x150
        batch_size=32,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='binary')
```

ì´ì œ ìœ„ generatorë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ labelingì„ í•´ì£¼ê³  ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

```Python
model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 300x300 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fifth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')
    tf.keras.layers.Dense(1, activation='sigmoid')
])
from tensorflow.keras.optimizers import RMSprop

model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(lr=0.001),
              metrics=['accuracy'])

history = model.fit(
      train_generator,
      steps_per_epoch=8,  
      epochs=15,
      verbose=1,
      validation_data = validation_generator,
      validation_steps=8)

```

ì˜µí‹°ë§ˆì´ì ¸ë¡œ AdamëŒ€ì‹  RMSprop ë¥¼ ì‚¬ìš©í•˜ì˜€ëŠ”ë°, ì´ëŠ” Learning Rateë¥¼ Gradient Descentë°©ë²•ì— ë”°ë¼ ë°”ê¾¸ì–´ì£¼ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë” ì•Œê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”. (Gradient Descent in Practice II Learning Rate by Andrew Ng: <https://goo.gle/3bQvJgM> )

ëª¨ë¸ í•™ìŠµì´ ëë‚˜ê³ , ì§ì ‘ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì„œ Prediction í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ì–´ë””ì„œ inferenceê°€ ì˜ëª»ëëŠ”ì§€ ë³´ê³  ëª¨ë¸ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```Python
import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():

  # predicting images
  path = '/content/' + fn
  img = image.load_img(path, target_size=(300, 300))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(classes[0])
  if classes[0]>0.5:
    print(fn + " is a human")
  else:
    print(fn + " is a horse")
```
![](/assets/images/2021-05-17-coursera-introduction-to-tensorflow-598cd377.png)
<center> <small> 6ê°œì˜ ì´ë¯¸ì§€ Prediction ê²°ê³¼ (ì¶œì²˜: https://youtu.be/0kYIZE8Gl90) </small> </center> <br/>

ìœ„ ì½”ë“œë¥¼ ì‚¬ìš©í•´ì„œ ë§ ì‚¬ì§„ 3ê°œ, ì‚¬ëŒ ì‚¬ì§„ 3ê°œë¥¼ í…ŒìŠ¤íŠ¸ í•œ ê²°ê³¼, ë§ ì‚¬ì§„ 3ê°œëŠ” ë§ê²Œ ë¶„ë¥˜í–ˆì§€ë§Œ, ì•„ë˜ ì‚¬ëŒ ì‚¬ì§„ì„ horseë¼ê³  ì˜ëª» ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤!

![](/assets/images/2021-05-17-coursera-introduction-to-tensorflow-dcbaf740.png)
<center> <small> ì˜¤ë¶„ë¥˜í•œ ì‚¬ëŒ ì‚¬ì§„ (ì¶œì²˜: https://youtu.be/0kYIZE8Gl90) </small> </center> <br/>

ì•„ë§ˆ ê¸´ ê¸ˆë°œ ë¨¸ë¦¬ì˜ íŠ¹ì§•ì´ í›ˆë ¨ì´ ì•ˆë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë‹¤ë¦¬ê°€ ë‚˜ì˜¤ì§€ ì•Šì€ ì¸ë¬¼ ì‚¬ì§„ì„ predictí–ˆì„ ë•Œë„ ë§ë¡œ ì˜¤ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” train ë°ì´í„°ì…‹ì—ë§Œ Over-Fittingëœ ë¬¸ì œì…ë‹ˆë‹¤. ì´ëŸ´ ë•ŒëŠ” ì–´ë””ê°€ ì˜ëª» í›ˆë ¨ë˜ì—ˆëŠ”ì§€ inferenceë¥¼ í†µí•´ ëª¨ë¸ì„ ë‹¤ì‹œ êµ¬ì„±í•´ì•¼í•©ë‹ˆë‹¤. ë˜í•œ Data augutationì„ ì‚¬ìš©í•´ì„œ ë” ë§ì€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ í•™ìŠµí•˜ë©´ Over-Fittingì„ ë°©ì§€í•  ìˆ˜ ìˆìœ¼ë©° ì´ëŠ” ë‹¤ìŒ ê°•ì˜ì—ì„œ ë‹¤ë¤„ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤.

-----------
## Course Certificate

![](/assets/images/2021-05-17-coursera-introduction-to-tensorflow-5c92122e.png)

ì´ë ‡ê²Œ ìˆ˜ë£Œì¦ì„ ë°œê¸‰ë°›ìœ¼ë©´ì„œ ë³¸ ì½”ìŠ¤ë¥¼ ì™„ê°•í–ˆìŠµë‹ˆë‹¤.ğŸ‘ êµ°ë”ë”ê¸°ì—†ëŠ” í˜„ì—… ì „ë¬¸ê°€(ê·¸ê²ƒë„ êµ¬ê¸€)ì˜ ê°•ì˜ë¡œ ê°œë…ì„ ì •ë¦¬í•˜ê³  ì£¼ì–´ì§„ ë°ì´í„°ì…‹ìœ¼ë¡œ ì§ì ‘ ì‹¤ìŠµ ë¬¸ì œë¥¼ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤. DeepLearning.AIì—ì„œ ì œê³µí•˜ëŠ” ë‹¤ë¥¸ ê°•ì˜ë„ ìˆ˜ê°•í•  ì˜ˆì •ì…ë‹ˆë‹¤.
